{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30ce5059",
   "metadata": {},
   "source": [
    "# 00. 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "6ca38f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de96e851",
   "metadata": {},
   "source": [
    "# 01. Transformer 구조 함수 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fb09b3",
   "metadata": {},
   "source": [
    "### Transformer  \n",
    "├── **Input Processing**  \n",
    "│   ├── Positional Encoding Layer  \n",
    "│   ├── Padding Mask  \n",
    "│   └── Look-ahead Mask  \n",
    "├── **Attention Mechanism**  \n",
    "│   ├── Scaled Dot Product Attention  \n",
    "│   └── Multi-Head Attention  \n",
    "├── **Encoder**  \n",
    "│   ├── Encoder Layer  \n",
    "│   │   ├── Multi-Head Attention (Self-Attention)  \n",
    "│   │   ├── Feed Forward Network  \n",
    "│   │   └── Add & Norm (Residual + Layer Normalization)  \n",
    "│   └── Stacking Encoder Layers  \n",
    "├── **Decoder**  \n",
    "│   ├── Decoder Layer  \n",
    "│   │   ├── Masked Multi-Head Attention (Self-Attention)  \n",
    "│   │   ├── Encoder-Decoder Attention  \n",
    "│   │   ├── Feed Forward Network  \n",
    "│   │   └── Add & Norm (Residual + Layer Normalization)  \n",
    "│   └── Stacking Decoder Layers  \n",
    "└── **Output Layer**  \n",
    "    └── Final Linear Layer + Softmax  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75751bf",
   "metadata": {},
   "source": [
    "## Input Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "ae23fd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "# Padding Mask 구현\n",
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "# Look-ahead Mask 구현\n",
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4450b831",
   "metadata": {},
   "source": [
    "## Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "b684f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "f18cfe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1988dbd3",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "2b284e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "04a7808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder layer * N개 쌓기\n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38235b32",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "d5025cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "d52a5901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder layer * N개 쌓기\n",
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4ce0e4",
   "metadata": {},
   "source": [
    "# 02. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "2e07ef14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 파일 로드\n",
    "chat_path = \"~/aiffel/transformer_chatbot/data/ChatbotData .csv\"\n",
    "data = pd.read_csv(chat_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "c51c5c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "챗봇 샘플의 개수 : 11823 \n",
      "\n",
      "Null 값 확인\n",
      " Q        0\n",
      "A        0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 샘플 개수와 null 값 확인\n",
    "print('챗봇 샘플의 개수 :', len(data),'\\n')\n",
    "print('Null 값 확인\\n',data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7683e4a",
   "metadata": {},
   "source": [
    "# 03. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "9282585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    # 입력받은 sentence 양쪽 공백을 제거\n",
    "    sentence = sentence.strip()\n",
    "    # 단어와 구두점 사이의 거리 생성\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    # 여러 공백을 하나의 공백으로 변환\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    # 한글, 숫자, 구두점(?, ., !, ,)을 제외한 모든 문자를 공백으로 대체\n",
    "    sentence = re.sub(r\"[^ㄱ-ㅎ가-힣0-9?.!,]\", \" \", sentence)\n",
    "    # 양쪽 공백을 제거하고 최종 결과 반환\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "8ba24dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 적용 및 Q, A 분리\n",
    "questions =[]\n",
    "answers=[]\n",
    "for idx, row in data.iterrows():\n",
    "    questions.append(preprocess_sentence(row['Q']))\n",
    "    answers.append(preprocess_sentence(row['A']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "9a88f4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 6695\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 3347\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 1673\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 836\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 418\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 209\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 104\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 52\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 26\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 13\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 6\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 3\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 4\n"
     ]
    }
   ],
   "source": [
    "# 질문과 답변 데이터 셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13)\n",
    "\n",
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "d8e78d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시작 토큰 번호 : [8161]\n",
      "종료 토큰 번호 : [8162]\n",
      "단어 집합의 크기 : 8163\n"
     ]
    }
   ],
   "source": [
    "print('시작 토큰 번호 :',START_TOKEN)\n",
    "print('종료 토큰 번호 :',END_TOKEN)\n",
    "print('단어 집합의 크기 :',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "fd195c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 각 문장의 길이를 계산하는 함수\n",
    "def calculate_sentence_length(sentences):\n",
    "    return [len(sentence.split()) for sentence in sentences]\n",
    "\n",
    "# 질문과 답변의 길이 계산\n",
    "question_lengths = calculate_sentence_length(questions)\n",
    "answer_lengths = calculate_sentence_length(answers)\n",
    "\n",
    "# 길이 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# 질문 길이 분포 히스토그램\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(question_lengths, bins=20, color='blue', alpha=0.7)\n",
    "plt.title('Question Length')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Questions')\n",
    "\n",
    "# 답변 길이 분포 히스토그램\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(answer_lengths, bins=20, color='green', alpha=0.7)\n",
    "plt.title('Answer Length')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Answers')\n",
    "\n",
    "# 질문 길이 박스플롯\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.boxplot(question_lengths, patch_artist=True, boxprops=dict(facecolor='lightblue'))\n",
    "plt.title('Question Length')\n",
    "plt.xlabel('Questions')\n",
    "plt.ylabel('Length')\n",
    "\n",
    "# 답변 길이 박스플롯\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.boxplot(answer_lengths, patch_artist=True, boxprops=dict(facecolor='lightgreen'))\n",
    "plt.title('Answer Length')\n",
    "plt.xlabel('Answers')\n",
    "plt.ylabel('Length')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "f28422e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩을 진행하고자 정의 -> 마스킹이 진행되므로 우선은 데이터의 가장 이상치인 30로 설정\n",
    "MAX_LENGTH = 15\n",
    "\n",
    "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩 함수화\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "    \n",
    "    # 최대 길이 30 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "        tokenized_inputs.append(sentence1)\n",
    "        tokenized_outputs.append(sentence2)\n",
    "\n",
    "  # 패딩 -> post로 적용\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "  return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "362e8e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8163\n",
      "질문 데이터의 크기(shape) : (11570, 15)\n",
      "답변 데이터의 크기(shape) : (11570, 15)\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('질문 데이터의 크기(shape) :', questions.shape)\n",
    "print('답변 데이터의 크기(shape) :', answers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "d5c05e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324e3a1a",
   "metadata": {},
   "source": [
    "# 05. Transformer 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "cb8c5d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "ff9789f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    4198144     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    5252864     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8163)   2097891     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 11,548,899\n",
      "Trainable params: 11,548,899\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼 파라미터 조정을 통한 모델 정의\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 4 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.2 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "d29c61f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss fuction -> 시퀀스에 패딩이 되어 있으므로 패딩 적용\n",
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "e9d96b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom learning rate\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "ed8c8187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률과 옵티마이저를 정의하고 모델 컴파일\n",
    "\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b9f3e0",
   "metadata": {},
   "source": [
    "# 05. Transformer 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "9fef0b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "181/181 [==============================] - 20s 52ms/step - loss: 3.9424 - accuracy: 0.0582\n",
      "Epoch 2/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 3.2321 - accuracy: 0.1170\n",
      "Epoch 3/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 2.7633 - accuracy: 0.1392\n",
      "Epoch 4/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.5818 - accuracy: 0.1448\n",
      "Epoch 5/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 2.4739 - accuracy: 0.1511\n",
      "Epoch 6/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 2.3810 - accuracy: 0.1561\n",
      "Epoch 7/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.2863 - accuracy: 0.1608\n",
      "Epoch 8/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 2.1806 - accuracy: 0.1669\n",
      "Epoch 9/80\n",
      "181/181 [==============================] - 10s 53ms/step - loss: 2.0579 - accuracy: 0.1762\n",
      "Epoch 10/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 1.9248 - accuracy: 0.1877\n",
      "Epoch 11/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 1.7785 - accuracy: 0.2008\n",
      "Epoch 12/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 1.6266 - accuracy: 0.2173\n",
      "Epoch 13/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 1.4783 - accuracy: 0.2345\n",
      "Epoch 14/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 1.3347 - accuracy: 0.2518\n",
      "Epoch 15/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 1.2011 - accuracy: 0.2692\n",
      "Epoch 16/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 1.0803 - accuracy: 0.2856\n",
      "Epoch 17/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 0.9786 - accuracy: 0.2974\n",
      "Epoch 18/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 0.8949 - accuracy: 0.3087\n",
      "Epoch 19/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 0.8219 - accuracy: 0.3185\n",
      "Epoch 20/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.7652 - accuracy: 0.3269\n",
      "Epoch 21/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 0.7239 - accuracy: 0.3330\n",
      "Epoch 22/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.6853 - accuracy: 0.3390\n",
      "Epoch 23/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.6543 - accuracy: 0.3430\n",
      "Epoch 24/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.6135 - accuracy: 0.3497\n",
      "Epoch 25/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.5777 - accuracy: 0.3553\n",
      "Epoch 26/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.5461 - accuracy: 0.3602\n",
      "Epoch 27/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 0.5207 - accuracy: 0.3632\n",
      "Epoch 28/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.4932 - accuracy: 0.3677\n",
      "Epoch 29/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.4657 - accuracy: 0.3722\n",
      "Epoch 30/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.4481 - accuracy: 0.3749\n",
      "Epoch 31/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.4302 - accuracy: 0.3768\n",
      "Epoch 32/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 0.4114 - accuracy: 0.3810\n",
      "Epoch 33/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 0.3925 - accuracy: 0.3840\n",
      "Epoch 34/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 0.3759 - accuracy: 0.3870\n",
      "Epoch 35/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 0.3603 - accuracy: 0.3897\n",
      "Epoch 36/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.3475 - accuracy: 0.3920\n",
      "Epoch 37/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.3339 - accuracy: 0.3952\n",
      "Epoch 38/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.3197 - accuracy: 0.3976\n",
      "Epoch 39/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.3090 - accuracy: 0.3990\n",
      "Epoch 40/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.2980 - accuracy: 0.4016\n",
      "Epoch 41/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 0.2896 - accuracy: 0.4036\n",
      "Epoch 42/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.2766 - accuracy: 0.4058\n",
      "Epoch 43/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 0.2657 - accuracy: 0.4083\n",
      "Epoch 44/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.2597 - accuracy: 0.4094\n",
      "Epoch 45/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.2505 - accuracy: 0.4116\n",
      "Epoch 46/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 0.2406 - accuracy: 0.4138\n",
      "Epoch 47/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.2355 - accuracy: 0.4146\n",
      "Epoch 48/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.2286 - accuracy: 0.4165\n",
      "Epoch 49/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.2211 - accuracy: 0.4183\n",
      "Epoch 50/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.2135 - accuracy: 0.4197\n",
      "Epoch 51/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.2108 - accuracy: 0.4208\n",
      "Epoch 52/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 0.2000 - accuracy: 0.4235\n",
      "Epoch 53/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.1977 - accuracy: 0.4231\n",
      "Epoch 54/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 0.1882 - accuracy: 0.4259\n",
      "Epoch 55/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 0.1826 - accuracy: 0.4273\n",
      "Epoch 56/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.1785 - accuracy: 0.4283\n",
      "Epoch 57/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.1715 - accuracy: 0.4300\n",
      "Epoch 58/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.1690 - accuracy: 0.4308\n",
      "Epoch 59/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.1659 - accuracy: 0.4310\n",
      "Epoch 60/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.1600 - accuracy: 0.4327\n",
      "Epoch 61/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.1583 - accuracy: 0.4329\n",
      "Epoch 62/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.1544 - accuracy: 0.4339\n",
      "Epoch 63/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.1481 - accuracy: 0.4357\n",
      "Epoch 64/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 0.1459 - accuracy: 0.4359\n",
      "Epoch 65/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.1424 - accuracy: 0.4367\n",
      "Epoch 66/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 0.1383 - accuracy: 0.4383\n",
      "Epoch 67/80\n",
      "181/181 [==============================] - 10s 53ms/step - loss: 0.1381 - accuracy: 0.4382\n",
      "Epoch 68/80\n",
      "181/181 [==============================] - 10s 53ms/step - loss: 0.1315 - accuracy: 0.4400\n",
      "Epoch 69/80\n",
      "181/181 [==============================] - 10s 53ms/step - loss: 0.1299 - accuracy: 0.4401\n",
      "Epoch 70/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 0.1242 - accuracy: 0.4415\n",
      "Epoch 71/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.1211 - accuracy: 0.4423\n",
      "Epoch 72/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.1209 - accuracy: 0.4424\n",
      "Epoch 73/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.1165 - accuracy: 0.4433\n",
      "Epoch 74/80\n",
      "181/181 [==============================] - 9s 50ms/step - loss: 0.1156 - accuracy: 0.4436\n",
      "Epoch 75/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.1121 - accuracy: 0.4447\n",
      "Epoch 76/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.1104 - accuracy: 0.4453\n",
      "Epoch 77/80\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 0.1074 - accuracy: 0.4461\n",
      "Epoch 78/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 0.1048 - accuracy: 0.4470\n",
      "Epoch 79/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 0.1030 - accuracy: 0.4476\n",
      "Epoch 80/80\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 0.1001 - accuracy: 0.4480\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "EPOCHS = 80\n",
    "\n",
    "history = model.fit(\n",
    "    dataset,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cdc1f1",
   "metadata": {},
   "source": [
    "# 06. 모델 평가하기 - 정성적 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "9a39238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트랜스 포머 모델에 전처리가 진행된 사용자의 입력을 전달하여 단어 예측 수행\n",
    "def evaluate(sentence):\n",
    "  # 입력 문장에 대한 전처리\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력 문장에 시작 토큰과 종료 토큰을 추가\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  output = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 예측 시작\n",
    "  for i in range(MAX_LENGTH):\n",
    "    predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "    # 현재 시점의 예측 단어를 받아온다.\n",
    "    predictions = predictions[:, -1:, :]\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 현재 시점의 예측 단어를 output(출력)에 연결한다.\n",
    "    # output은 for문의 다음 루프에서 디코더의 입력이 된다.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  # 단어 예측이 모두 끝났다면 output을 리턴.\n",
    "  return tf.squeeze(output, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "e93ea304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 수행한 결과를 출력하는 함수\n",
    "def Q1(sentence):\n",
    "  prediction = evaluate(sentence)\n",
    "\n",
    "  # prediction == 디코더가 리턴한 챗봇의 대답에 해당하는 정수 시퀀스\n",
    "  # tokenizer.decode()를 통해 정수 시퀀스를 문자열로 디코딩.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력: {}'.format(sentence))\n",
    "  print('출력: {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "aa4e7b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: 안녕하세요\n",
      "출력: 안녕하세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'안녕하세요 .'"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1('안녕하세요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "8cc387e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: 밥 먹었어?\n",
      "출력: 저는 배터리가 밥이예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저는 배터리가 밥이예요 .'"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1('밥 먹었어?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "06779c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: 저녁은 뭐 먹을까?\n",
      "출력: 맛있는 거 드세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'맛있는 거 드세요 .'"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1('저녁은 뭐 먹을까?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "cf959fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: 고민이 있어..\n",
      "출력: 잘 알아보고 사세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'잘 알아보고 사세요 .'"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1('고민이 있어..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2e9b7b",
   "metadata": {},
   "source": [
    "### 결과 :  Epochs 수를 적당하게만 설정하였는데도 나쁘지 않은 성능을 보여준다. 정성적인 평가를 진행한 결과는 입력한 문장과 관련된 답변을 내뱉음과 동시에 깔끔한 문장의 맺음을 확인 할 수 있다. 그러나 한국어에 적응을 한 모델인가에 대한 아쉬움이 있다. 대화를 시도할 때 사람은 원하는 답변을 어느정도는 생각해두며 물어보려는 경향을 가질 것이라고 생각한다. 이러한 경향을 가진 사람이 답변을 받았을 때 만족도로 평가한다면 그리 높지는 않은 답변에 경우 일 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca9091e",
   "metadata": {},
   "source": [
    "## 회고\n",
    "### 토큰은 범용적인 서브워드 텍스트 인코더를 사용하여 한국어 대화에 완전한 답변을 얻을 수 있는 경우가 생기는 것을 확인하였고 나름 만족스러웠다. 그러나 한국어에 형태와 관련된 완전한 학습을 진행하였나? 하는 의문이 드는 대답은 어느정도 있었다. 또한 검증과 정량적인 평가 지표를 어떻게 얻을 수 있을까에 대한 의문도 생겼다. 이러한 해결 방법에 대한 추가적인 고찰이 필요하다고 느꼈다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68a6bc7",
   "metadata": {},
   "source": [
    "# (번외) 07. 토크나이저 변경 - 시간 아깝다..ㅜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "e2739e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.9/site-packages (4.8.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.9/site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (1.21.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in /opt/conda/lib/python3.9/site-packages (from transformers) (0.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from huggingface-hub==0.0.12->transformers) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->transformers) (3.0.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (8.0.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: gluonnlp in /opt/conda/lib/python3.9/site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.9/site-packages (from gluonnlp) (1.21.4)\n",
      "Requirement already satisfied: cython in /opt/conda/lib/python3.9/site-packages (from gluonnlp) (0.29.24)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from gluonnlp) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->gluonnlp) (3.0.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting git+https://github.com/SKTBrain/KoBERT.git\n",
      "  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-req-build-wqze0oo6\n",
      "  Running command git clone --filter=blob:none -q https://github.com/SKTBrain/KoBERT.git /tmp/pip-req-build-wqze0oo6\n",
      "  Resolved https://github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: boto3<=1.15.18 in /opt/conda/lib/python3.9/site-packages (from kobert==0.2.3) (1.15.18)\n",
      "Requirement already satisfied: gluonnlp<=0.10.0,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from kobert==0.2.3) (0.10.0)\n",
      "Requirement already satisfied: mxnet<=1.7.0.post2,>=1.4.0 in /opt/conda/lib/python3.9/site-packages (from kobert==0.2.3) (1.7.0.post2)\n",
      "Requirement already satisfied: onnxruntime<=1.8.0,==1.8.0 in /opt/conda/lib/python3.9/site-packages (from kobert==0.2.3) (1.8.0)\n",
      "Requirement already satisfied: sentencepiece<=0.1.96,>=0.1.6 in /opt/conda/lib/python3.9/site-packages (from kobert==0.2.3) (0.1.96)\n",
      "Requirement already satisfied: torch<=1.10.1,>=1.7.0 in /opt/conda/lib/python3.9/site-packages (from kobert==0.2.3) (1.9.1+cu111)\n",
      "Requirement already satisfied: transformers<=4.8.1,>=4.8.1 in /opt/conda/lib/python3.9/site-packages (from kobert==0.2.3) (4.8.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.9/site-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.21.4)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.9/site-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (3.19.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.9/site-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.12)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.9/site-packages (from boto3<=1.15.18->kobert==0.2.3) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from boto3<=1.15.18->kobert==0.2.3) (0.3.7)\n",
      "Requirement already satisfied: botocore<1.19.0,>=1.18.18 in /opt/conda/lib/python3.9/site-packages (from boto3<=1.15.18->kobert==0.2.3) (1.18.18)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (21.3)\n",
      "Requirement already satisfied: cython in /opt/conda/lib/python3.9/site-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (0.29.24)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /opt/conda/lib/python3.9/site-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (0.8.4)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /opt/conda/lib/python3.9/site-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.26.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch<=1.10.1,>=1.7.0->kobert==0.2.3) (4.0.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.62.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (2021.11.10)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.9/site-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.10.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.4.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.9/site-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.0.46)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in /opt/conda/lib/python3.9/site-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.0.12)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20 in /opt/conda/lib/python3.9/site-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.25.11)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.9/site-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (3.0.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.0.8)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.1.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (8.0.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install gluonnlp\n",
    "!pip install git+https://github.com/SKTBrain/KoBERT.git\n",
    "\n",
    "from kobert import get_tokenizer\n",
    "from transformers import BertModel\n",
    "from gluonnlp.data import SentencepieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "3afe0c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 적용 및 Q, A 분리\n",
    "questions_a =[]\n",
    "answers_a=[]\n",
    "for idx, row in data.iterrows():\n",
    "    questions_a.append(preprocess_sentence(row['Q']))\n",
    "    answers_a.append(preprocess_sentence(row['A']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "79f10f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /aiffel/aiffel/transformer_chatbot/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "첫 번째 질문의 토큰화 결과: [2, '▁12', '시', '▁', '땡', '▁', '!', 3]\n",
      "첫 번째 답변의 토큰화 결과: [2, '▁하루', '가', '▁또', '▁', '가', '네요', '▁', '.', 3]\n"
     ]
    }
   ],
   "source": [
    "# KoBERT 토크나이저 가져오기\n",
    "tokenizer_path = get_tokenizer()\n",
    "sp_tokenizer = SentencepieceTokenizer(tokenizer_path)\n",
    "\n",
    "# KoBERT 토크나이저를 사용해 질문과 답변 데이터 토크나이징\n",
    "questions_tokenized_a = [sp_tokenizer(sentence) for sentence in questions_a]\n",
    "answers_tokenized_a = [sp_tokenizer(sentence) for sentence in answers_a]\n",
    "\n",
    "# KoBERT에서 시작 토큰과 종료 토큰을 추가하기 위한 설정\n",
    "START_TOKEN = [2]  # KoBERT에서 사용하는 CLS 토큰 ID\n",
    "END_TOKEN = [3]    # KoBERT에서 사용하는 SEP 토큰 ID\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 각 질문과 답변에 추가\n",
    "questions_tokenized_a = [START_TOKEN + tokens + END_TOKEN for tokens in questions_tokenized_a]\n",
    "answers_tokenized_a = [START_TOKEN + tokens + END_TOKEN for tokens in answers_tokenized_a]\n",
    "\n",
    "# VOCAB_SIZE를 KoBERT 토크나이저 기반으로 설정\n",
    "VOCAB_SIZE = len(sp_tokenizer)\n",
    "\n",
    "# 예시: 첫 번째 질문 및 답변 토큰화 결과 출력\n",
    "print(\"첫 번째 질문의 토큰화 결과:\", questions_tokenized_a[0])\n",
    "print(\"첫 번째 답변의 토큰화 결과:\", answers_tokenized_a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "ef4e226a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시작 토큰 번호 : [8002]\n",
      "종료 토큰 번호 : [8003]\n",
      "단어 집합의 크기 : 8004\n"
     ]
    }
   ],
   "source": [
    "print('시작 토큰 번호 :',START_TOKEN_A)\n",
    "print('종료 토큰 번호 :',END_TOKEN_A)\n",
    "print('단어 집합의 크기 :',VOCAB_SIZE_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "be0db9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 각 문장의 토큰 개수를 계산하는 함수\n",
    "def calculate_sentence_length(sentences):\n",
    "    return [len(sentence) for sentence in sentences]\n",
    "\n",
    "# 질문과 답변의 길이 계산\n",
    "question_lengths = calculate_sentence_length(questions_tokenized_a)\n",
    "answer_lengths = calculate_sentence_length(answers_tokenized_a)\n",
    "\n",
    "# 길이 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# 질문 길이 분포 히스토그램\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(question_lengths, bins=20, color='blue', alpha=0.7)\n",
    "plt.title('Question Length')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Questions')\n",
    "\n",
    "# 답변 길이 분포 히스토그램\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(answer_lengths, bins=20, color='green', alpha=0.7)\n",
    "plt.title('Answer Length')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Answers')\n",
    "\n",
    "# 질문 길이 박스플롯\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.boxplot(question_lengths, patch_artist=True, boxprops=dict(facecolor='lightblue'))\n",
    "plt.title('Question Length')\n",
    "plt.xlabel('Questions')\n",
    "plt.ylabel('Length')\n",
    "\n",
    "# 답변 길이 박스플롯\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.boxplot(answer_lengths, patch_artist=True, boxprops=dict(facecolor='lightgreen'))\n",
    "plt.title('Answer Length')\n",
    "plt.xlabel('Answers')\n",
    "plt.ylabel('Length')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "7ba4fa4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8002\n",
      "질문 데이터의 크기(shape) : 11338\n",
      "답변 데이터의 크기(shape) : 11338\n"
     ]
    }
   ],
   "source": [
    "# 패딩을 진행하고자 정의 -> 마스킹이 진행되므로 우선은 데이터의 가장 이상치인 30로 설정\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "# Tokenize and filter 함수 구현\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        sentence1 = START_TOKEN + sp_tokenizer(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + sp_tokenizer(sentence2) + END_TOKEN\n",
    "\n",
    "        # 길이를 MAX_LENGTH로 제한\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "\n",
    "    return tokenized_inputs, tokenized_outputs\n",
    "\n",
    "questions_a, answers_a = tokenize_and_filter(questions_a, answers_a)\n",
    "\n",
    "print('단어장의 크기 :', (VOCAB_SIZE))\n",
    "print('질문 데이터의 크기(shape) :', len(questions_a))\n",
    "print('답변 데이터의 크기(shape) :', len(answers_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "0f2ba777",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "not a string",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/2756290747.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# 질문과 답변을 정수 ID로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mquestions_tokenized_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0manswers_tokenized_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswers_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31/2756290747.py\u001b[0m in \u001b[0;36mtokenize_to_ids\u001b[0;34m(sentences, sp_tokenizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# 문장을 정수 ID로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mtokenized_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/gluonnlp/data/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \"\"\"\n\u001b[0;32m--> 560\u001b[0;31m         return self._processor.SampleEncodeAsPieces(sample, self._nbest,\n\u001b[0m\u001b[1;32m    561\u001b[0m                                                     self._alpha)\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sentencepiece/__init__.py\u001b[0m in \u001b[0;36mSampleEncodeAsPieces\u001b[0;34m(self, input, nbest_size, alpha)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mSampleEncodeAsPieces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_sentencepiece\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentencePieceProcessor_SampleEncodeAsPieces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mSampleEncodeAsIds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: not a string"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE_A = 32\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# KoBERT에서 문자열 토큰을 정수 ID로 변환하는 함수\n",
    "def tokenize_to_ids(sentences, sp_tokenizer):\n",
    "    tokenized_ids = []\n",
    "    for sentence in sentences:\n",
    "        # 문장을 정수 ID로 변환\n",
    "        tokens = sp_tokenizer(sentence)\n",
    "        tokenized_ids.append(tokens)\n",
    "    return tokenized_ids\n",
    "\n",
    "# 질문과 답변을 정수 ID로 변환\n",
    "questions_tokenized_a = tokenize_to_ids(questions_a, sp_tokenizer)\n",
    "answers_tokenized_a = tokenize_to_ids(answers_a, sp_tokenizer)\n",
    "\n",
    "# 패딩을 적용하여 모든 문장의 길이를 동일하게 설정\n",
    "questions_padded = pad_sequences(questions_tokenized_a, maxlen=MAX_LENGTH, padding='post')\n",
    "answers_padded = pad_sequences(answers_tokenized_a, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
    "dataset_newtoken = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions_padded,\n",
    "        'dec_inputs': answers_padded[:, :-1]  # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers_padded[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset_newtoken = dataset_newtoken.cache()\n",
    "dataset_newtoken = dataset_newtoken.shuffle(BUFFER_SIZE)\n",
    "dataset_newtoken = dataset_newtoken.batch(BATCH_SIZE_A)\n",
    "dataset_newtoken = dataset_newtoken.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3297f97",
   "metadata": {},
   "source": [
    "## 해결 실패.. BERT 를 나중에 공부해야 해결할 수 있을 것 같다.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "1cf4addb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    4156928     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    5211648     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8002)   2056514     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 11,425,090\n",
      "Trainable params: 11,425,090\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼 파라미터 조정을 통한 모델 정의\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 4  # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256  # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8  # 멀티 헤드 어텐션에서의 헤드 수\n",
    "UNITS = 512  # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.2  # 드롭아웃의 비율\n",
    "\n",
    "# 모델 정의\n",
    "model_newtoken = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "\n",
    "model_newtoken.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "d3b3c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률과 옵티마이저를 정의하고 모델 컴파일\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model_newtoken.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "8719fe4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "369/369 [==============================] - 26s 43ms/step - loss: nan - accuracy: 0.6414\n",
      "Epoch 2/5\n",
      "369/369 [==============================] - 16s 43ms/step - loss: nan - accuracy: 0.6432\n",
      "Epoch 3/5\n",
      "369/369 [==============================] - 16s 44ms/step - loss: nan - accuracy: 0.6432\n",
      "Epoch 4/5\n",
      "369/369 [==============================] - 16s 43ms/step - loss: nan - accuracy: 0.6432\n",
      "Epoch 5/5\n",
      "369/369 [==============================] - 16s 45ms/step - loss: nan - accuracy: 0.6432\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "EPOCHS = 5\n",
    "\n",
    "history = model_newtoken.fit(\n",
    "    dataset_newtoken,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54364df1",
   "metadata": {},
   "source": [
    "### Loss가 nan이 나오는 이유는 토큰화 진행 후 학습 과정에서 토큰나이저가 달라 학습과정에서의 오류가 났을 가능성이 높다고 판단한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "a01258b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트랜스포머 모델에 전처리가 진행된 사용자의 입력을 전달하여 단어 예측 수행\n",
    "def evaluate_newtoken(sentence):\n",
    "    # sp_tokenizer는 문장을 토큰화한 후 정수 리스트를 반환합니다.\n",
    "    sentence_tokens = sp_tokenizer(sentence)\n",
    "\n",
    "    # START_TOKEN과 END_TOKEN이 정수 리스트인지 확인\n",
    "    sentence = tf.expand_dims(\n",
    "        START_TOKEN + sentence_tokens + END_TOKEN, axis=0\n",
    "    )\n",
    "\n",
    "    output = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    for i in range(MAX_LENGTH):\n",
    "        predictions = model_newtoken(inputs=[sentence, output], training=False)\n",
    "\n",
    "        # 예측 결과에서 마지막 단어 선택\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 예측한 단어가 종료 토큰이라면 예측을 중단합니다.\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        # 예측한 단어를 출력에 연결합니다.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "148a0ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 수행한 결과를 출력하는 함수\n",
    "def Q2(sentence):\n",
    "    prediction = evaluate_newtoken(sentence)\n",
    "    \n",
    "    # 예측 결과를 디코딩해서 사람이 읽을 수 있는 문장으로 변환\n",
    "    predicted_sentence = sp_tokenizer.DecodeIds(prediction.numpy().tolist())\n",
    "\n",
    "    print('입력: {}'.format(sentence))\n",
    "    print('출력: {}'.format(predicted_sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "23e79d26",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't convert Python sequence with mixed types to Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/3044490931.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 예시 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mQ2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'저녁은 뭐 먹을까?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_31/3693266390.py\u001b[0m in \u001b[0;36mQ2\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 예측 수행한 결과를 출력하는 함수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mQ2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_newtoken\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# 예측 결과를 디코딩해서 사람이 읽을 수 있는 문장으로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31/3044904251.py\u001b[0m in \u001b[0;36mevaluate_newtoken\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# START_TOKEN과 END_TOKEN이 정수 리스트인지 확인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     sentence = tf.expand_dims(\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mSTART_TOKEN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msentence_tokens\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mEND_TOKEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     )\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mexpand_dims_v2\u001b[0;34m(input, axis, name)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0mInvalidArgumentError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mout\u001b[0m \u001b[0mof\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m   \"\"\"\n\u001b[0;32m--> 437\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mexpand_dims\u001b[0;34m(input, axis, name)\u001b[0m\n\u001b[1;32m   2291\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2292\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2293\u001b[0;31m       return expand_dims_eager_fallback(\n\u001b[0m\u001b[1;32m   2294\u001b[0m           input, axis, name=name, ctx=_ctx)\n\u001b[1;32m   2295\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mexpand_dims_eager_fallback\u001b[0;34m(input, axis, name, ctx)\u001b[0m\n\u001b[1;32m   2312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2313\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexpand_dims_eager_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2314\u001b[0;31m   \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2315\u001b[0m   \u001b[0m_attr_Tdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, allowed_dtypes, default_dtype)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         tensor = ops.convert_to_tensor(\n\u001b[0m\u001b[1;32m    274\u001b[0m             t, dtype, preferred_dtype=default_dtype, ctx=ctx)\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    344\u001b[0m                                          as_ref=False):\n\u001b[1;32m    345\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't convert Python sequence with mixed types to Tensor."
     ]
    }
   ],
   "source": [
    "# 예시 실행\n",
    "Q2('저녁은 뭐 먹을까?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd43be2",
   "metadata": {},
   "source": [
    "## 퍼실님게 문의해본 결과.. koBERT는 토큰화 과정이 다르므로 모델 구현 함수에 그대로 적용할 시 오류 가능성이 높다고 한다. 따로 처리해 주어야할 내용이 많아 BERT를 공부한 뒤 진행하는 것을 추천하셨다.. 근데 저는 CV 가고 싶어요..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cea3b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed910927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e12847d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
