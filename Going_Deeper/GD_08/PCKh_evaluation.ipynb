{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9be4527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tqdm import tqdm  # 진행률 표시를 위한 라이브러리\n",
    "\n",
    "import io, json, os, math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Add, Concatenate, Lambda\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, MaxPool2D\n",
    "from tensorflow.keras.layers import UpSampling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import ray\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "# 경로 설정\n",
    "PROJECT_PATH = os.getenv('HOME') + '/aiffel/mpii'\n",
    "IMAGE_PATH = os.path.join(PROJECT_PATH, 'images')\n",
    "MODEL_PATH = os.path.join(PROJECT_PATH, 'model')\n",
    "VALID_JSON = os.path.join(PROJECT_PATH, 'mpii_human_pose_v1_u12_2', 'validation.json')\n",
    "WEIGHTS_PATH_A = os.path.join(MODEL_PATH, 'model-epoch-9-loss-1.1228.h5') \n",
    "WEIGHTS_PATH = os.path.join(MODEL_PATH, 'model_simplebaseline-epoch-9-loss-0.2786.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f94a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BottleneckBlock(inputs, filters, strides=1, downsample=False, name=None):\n",
    "    identity = inputs\n",
    "    if downsample:\n",
    "        identity = Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=1,\n",
    "            strides=strides,\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal')(inputs)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.9)(inputs)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(\n",
    "        filters=filters // 2,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(x)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(\n",
    "        filters=filters // 2,\n",
    "        kernel_size=3,\n",
    "        strides=strides,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(x)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(x)\n",
    "\n",
    "    x = Add()([identity, x])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4dc2dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HourglassModule(inputs, order, filters, num_residual):\n",
    "    \n",
    "    up1 = BottleneckBlock(inputs, filters, downsample=False)\n",
    "    for i in range(num_residual):\n",
    "        up1 = BottleneckBlock(up1, filters, downsample=False)\n",
    "\n",
    "    low1 = MaxPool2D(pool_size=2, strides=2)(inputs)\n",
    "    for i in range(num_residual):\n",
    "        low1 = BottleneckBlock(low1, filters, downsample=False)\n",
    "\n",
    "    low2 = low1\n",
    "    if order > 1:\n",
    "        low2 = HourglassModule(low1, order - 1, filters, num_residual)\n",
    "    else:\n",
    "        for i in range(num_residual):\n",
    "            low2 = BottleneckBlock(low2, filters, downsample=False)\n",
    "\n",
    "    low3 = low2\n",
    "    for i in range(num_residual):\n",
    "        low3 = BottleneckBlock(low3, filters, downsample=False)\n",
    "\n",
    "    up2 = UpSampling2D(size=2)(low3)\n",
    "\n",
    "    return up2 + up1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d2a3202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearLayer(inputs, filters):\n",
    "    x = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8efaa21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def StackedHourglassNetwork(\n",
    "        input_shape=(256, 256, 3), \n",
    "        num_stack=4, \n",
    "        num_residual=1,\n",
    "        num_heatmap=16):\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=7,\n",
    "        strides=2,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BottleneckBlock(x, 128, downsample=True)\n",
    "    x = MaxPool2D(pool_size=2, strides=2)(x)\n",
    "    x = BottleneckBlock(x, 128, downsample=False)\n",
    "    x = BottleneckBlock(x, 256, downsample=True)\n",
    "\n",
    "    ys = []\n",
    "    for i in range(num_stack):\n",
    "        x = HourglassModule(x, order=4, filters=256, num_residual=num_residual)\n",
    "        for i in range(num_residual):\n",
    "            x = BottleneckBlock(x, 256, downsample=False)\n",
    "\n",
    "        x = LinearLayer(x, 256)\n",
    "\n",
    "        y = Conv2D(\n",
    "            filters=num_heatmap,\n",
    "            kernel_size=1,\n",
    "            strides=1,\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal')(x)\n",
    "        ys.append(y)\n",
    "\n",
    "        if i < num_stack - 1:\n",
    "            y_intermediate_1 = Conv2D(filters=256, kernel_size=1, strides=1)(x)\n",
    "            y_intermediate_2 = Conv2D(filters=256, kernel_size=1, strides=1)(y)\n",
    "            x = Add()([y_intermediate_1, y_intermediate_2])\n",
    "\n",
    "    return tf.keras.Model(inputs, ys, name='stacked_hourglass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06b2cdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimpleBaseline(input_shape=(256, 256, 3), num_heatmap=16):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # Backbone: ResNet50 without top layers\n",
    "    backbone = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_tensor=inputs)\n",
    "\n",
    "    x = backbone.output\n",
    "\n",
    "    # Deconvolution layers to upsample\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=256, kernel_size=4, strides=2, padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=256, kernel_size=4, strides=2, padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=256, kernel_size=4, strides=2, padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Final convolution to get the heatmap\n",
    "    outputs = tf.keras.layers.Conv2D(filters=num_heatmap, kernel_size=1, strides=1, padding='same', activation=None)(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name='simple_baseline')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc9e6308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증용 어노테이션 로드\n",
    "with open(VALID_JSON) as val_json:\n",
    "    val_annos = json.load(val_json)\n",
    "\n",
    "# 이미지 전처리 함수 정의\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = image.resize((256, 256))\n",
    "    image = np.array(image)\n",
    "    image = image.astype(np.float32) / 255.0  # Normalize to [0,1]\n",
    "    return image\n",
    "\n",
    "# 키포인트 추출 함수 정의\n",
    "def extract_keypoints_from_heatmap(heatmaps):\n",
    "    num_heatmap = heatmaps.shape[-1]\n",
    "    keypoints = []\n",
    "    for i in range(num_heatmap):\n",
    "        heatmap = heatmaps[:, :, i]\n",
    "        y, x = np.unravel_index(np.argmax(heatmap), heatmap.shape)\n",
    "        keypoints.append((x, y))\n",
    "    return keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15c9750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pckh(pred_keypoints, gt_keypoints, head_size, threshold=0.5):\n",
    "    num_keypoints = len(gt_keypoints)\n",
    "    correct_keypoints = 0\n",
    "    total_keypoints = 0\n",
    "\n",
    "    for i in range(num_keypoints):\n",
    "        # 관절점이 가려져 있는 경우 제외\n",
    "        if gt_keypoints[i][2] == 0:\n",
    "            continue\n",
    "\n",
    "        pred_x, pred_y = pred_keypoints[i]\n",
    "        gt_x, gt_y, visibility = gt_keypoints[i]\n",
    "\n",
    "        # 유클리드 거리 계산\n",
    "        distance = np.sqrt((pred_x - gt_x) ** 2 + (pred_y - gt_y) ** 2)\n",
    "\n",
    "        # 헤드 크기로 정규화\n",
    "        normalized_distance = distance / head_size\n",
    "\n",
    "        # 임계값보다 작은 경우 정확한 키포인트로 간주\n",
    "        if normalized_distance <= threshold:\n",
    "            correct_keypoints += 1\n",
    "\n",
    "        total_keypoints += 1\n",
    "\n",
    "    return correct_keypoints, total_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6af9a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked Hourglass 모델 로드\n",
    "num_heatmap = 16\n",
    "IMAGE_SHAPE = (256, 256, 3)\n",
    "model = StackedHourglassNetwork(IMAGE_SHAPE, 4, 1, num_heatmap)\n",
    "model.load_weights(WEIGHTS_PATH_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de8a0474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2958/2958 [06:12<00:00,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCKh@0.5: 20.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 전체 PCKh 계산\n",
    "total_correct_keypoints = 0\n",
    "total_keypoints = 0\n",
    "\n",
    "for anno in tqdm(val_annos):\n",
    "    filename = anno['image']\n",
    "    filepath = os.path.join(IMAGE_PATH, filename)\n",
    "    image = preprocess_image(filepath)\n",
    "\n",
    "    # 원본 이미지 크기\n",
    "    original_image = Image.open(filepath)\n",
    "    original_width, original_height = original_image.size\n",
    "\n",
    "    # 예측 수행\n",
    "    inputs = np.expand_dims(image, axis=0)\n",
    "    outputs = model.predict(inputs)\n",
    "    heatmaps = outputs[-1]  # 배치 차원 제거\n",
    "    heatmaps = np.squeeze(heatmaps, axis=0)  # heatmaps shape: (64, 64, 16)\n",
    "    # 키포인트 추출\n",
    "    pred_keypoints = extract_keypoints_from_heatmap(heatmaps)\n",
    "\n",
    "    # 키포인트 좌표를 원본 이미지 크기로 변환\n",
    "    pred_keypoints_scaled = []\n",
    "    for (x, y) in pred_keypoints:\n",
    "        x_orig = x / heatmaps.shape[1] * original_width\n",
    "        y_orig = y / heatmaps.shape[0] * original_height\n",
    "        pred_keypoints_scaled.append((x_orig, y_orig))\n",
    "\n",
    "    # 실제 키포인트 가져오기\n",
    "    gt_joints = anno['joints']  # [[x0, y0], [x1, y1], ..., [x15, y15]]\n",
    "    gt_vis = anno['joints_vis']  # [v0, v1, ..., v15]\n",
    "    gt_keypoints = []\n",
    "    for i in range(len(gt_joints)):\n",
    "        x, y = gt_joints[i]\n",
    "        v = gt_vis[i]\n",
    "        gt_keypoints.append((x, y, v))\n",
    "\n",
    "    # 헤드 크기 계산 (머리 위쪽과 목의 거리)\n",
    "    head_top = np.array(gt_joints[9])  # Head top\n",
    "    upper_neck = np.array(gt_joints[8])  # Upper neck\n",
    "    head_size = np.linalg.norm(head_top - upper_neck)\n",
    "\n",
    "    # 만약 헤드 크기가 0이면 스킵\n",
    "    if head_size == 0:\n",
    "        continue\n",
    "\n",
    "    # PCKh 계산\n",
    "    correct_kps, total_kps = compute_pckh(pred_keypoints_scaled, gt_keypoints, head_size, threshold=0.5)\n",
    "    total_correct_keypoints += correct_kps\n",
    "    total_keypoints += total_kps\n",
    "\n",
    "# 최종 PCKh 계산\n",
    "pckh = total_correct_keypoints / total_keypoints if total_keypoints > 0 else 0\n",
    "print(f'PCKh@0.5: {pckh * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8acfc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple baseline 모델 로드\n",
    "num_heatmap = 16\n",
    "IMAGE_SHAPE = (256, 256, 3)\n",
    "model = SimpleBaseline(IMAGE_SHAPE, num_heatmap)\n",
    "model.load_weights(WEIGHTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d2b68d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2958/2958 [04:54<00:00, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCKh@0.5: 21.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 전체 PCKh 계산\n",
    "total_correct_keypoints = 0\n",
    "total_keypoints = 0\n",
    "\n",
    "for anno in tqdm(val_annos):\n",
    "    filename = anno['image']\n",
    "    filepath = os.path.join(IMAGE_PATH, filename)\n",
    "    image = preprocess_image(filepath)\n",
    "\n",
    "    # 원본 이미지 크기\n",
    "    original_image = Image.open(filepath)\n",
    "    original_width, original_height = original_image.size\n",
    "\n",
    "    # 예측 수행\n",
    "    inputs = np.expand_dims(image, axis=0)\n",
    "    outputs = model.predict(inputs)\n",
    "    heatmaps = outputs[0]  # 배치 차원 제거\n",
    "\n",
    "    # 키포인트 추출\n",
    "    pred_keypoints = extract_keypoints_from_heatmap(heatmaps)\n",
    "\n",
    "    # 키포인트 좌표를 원본 이미지 크기로 변환\n",
    "    pred_keypoints_scaled = []\n",
    "    for (x, y) in pred_keypoints:\n",
    "        x_orig = x / heatmaps.shape[1] * original_width\n",
    "        y_orig = y / heatmaps.shape[0] * original_height\n",
    "        pred_keypoints_scaled.append((x_orig, y_orig))\n",
    "\n",
    "    # 실제 키포인트 가져오기\n",
    "    gt_joints = anno['joints']  # [[x0, y0], [x1, y1], ..., [x15, y15]]\n",
    "    gt_vis = anno['joints_vis']  # [v0, v1, ..., v15]\n",
    "    gt_keypoints = []\n",
    "    for i in range(len(gt_joints)):\n",
    "        x, y = gt_joints[i]\n",
    "        v = gt_vis[i]\n",
    "        gt_keypoints.append((x, y, v))\n",
    "\n",
    "    # 헤드 크기 계산 (머리 위쪽과 목의 거리)\n",
    "    head_top = np.array(gt_joints[9])  # Head top\n",
    "    upper_neck = np.array(gt_joints[8])  # Upper neck\n",
    "    head_size = np.linalg.norm(head_top - upper_neck)\n",
    "\n",
    "    # 만약 헤드 크기가 0이면 스킵\n",
    "    if head_size == 0:\n",
    "        continue\n",
    "\n",
    "    # PCKh 계산\n",
    "    correct_kps, total_kps = compute_pckh(pred_keypoints_scaled, gt_keypoints, head_size, threshold=0.5)\n",
    "    total_correct_keypoints += correct_kps\n",
    "    total_keypoints += total_kps\n",
    "\n",
    "# 최종 PCKh 계산\n",
    "pckh = total_correct_keypoints / total_keypoints if total_keypoints > 0 else 0\n",
    "print(f'PCKh@0.5: {pckh * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
